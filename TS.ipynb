{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tabu Search of the Eggholder Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sys import path_importer_cache\n",
    "import os\n",
    "import eggholder as egg\n",
    "import init_archive as inar\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tabu Search Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_array(array, list_of_arrays):\n",
    "    '''Check if an array (x) is in a list of arrays.'''\n",
    "    return any(np.array_equal(array, a) for a in list_of_arrays)\n",
    "\n",
    "def poss_steps(d, step):\n",
    "    '''returns a vector of possible steps to make.'''\n",
    "    poss_steps = []\n",
    "    for i in range(d):\n",
    "        new = np.zeros(d)\n",
    "        new[i] = step\n",
    "        poss_steps.append(new.copy())\n",
    "        new[i] = -step\n",
    "        poss_steps.append(new.copy())\n",
    "    return poss_steps\n",
    "\n",
    "def search(base, step, STM, x_best, fx_best, constrained, f_evals_count, w_val):\n",
    "    '''evaluates a step in the given step direction.'''\n",
    "    try:\n",
    "        x_new = base + step\n",
    "        if not in_array(x_new, STM):\n",
    "            if constrained:\n",
    "                fx_new = egg.eggholder(x_new)\n",
    "            else:\n",
    "                fx_new = egg.eggholder_unconstrained(x_new, w_val)\n",
    "            f_evals_count += 1\n",
    "            if fx_best == None:\n",
    "                x_best = x_new.copy()\n",
    "                fx_best = fx_new.copy() \n",
    "            if fx_new < fx_best:\n",
    "                x_best = x_new.copy()\n",
    "                fx_best = fx_new.copy()\n",
    "    except AssertionError:\n",
    "        print(\"not in bounds.\")\n",
    "        pass\n",
    "    \n",
    "    return x_best, fx_best, f_evals_count\n",
    "\n",
    "def pattern(x_best, fx_best, base, constrained, w_val, f_evals_count):\n",
    "    '''perform a pattern move in the specified direction.'''\n",
    "    try:\n",
    "        pattern_move = 2*x_best[1] - base\n",
    "        if constrained:\n",
    "            f_pattern = egg.eggholder(pattern_move)\n",
    "        else:\n",
    "            f_pattern = egg.eggholder_unconstrained(pattern_move, w_val)\n",
    "        f_evals_count += 1\n",
    "        if f_pattern < fx_best:\n",
    "            fx_best  = f_pattern\n",
    "            x_best = pattern_move\n",
    "    except AssertionError:\n",
    "        print(\"not in bounds.\")\n",
    "        pass\n",
    "\n",
    "    return x_best, fx_best, f_evals_count\n",
    "\n",
    "def local_search_basic(base, f_base, d, STM, steps, f_evals_count, constrained, w_val):\n",
    "    '''Perform a local search step for the tabu search function.\n",
    "    inputs\n",
    "        base:           d-length vector     current point x\n",
    "        f_base:         float               function evaluated at x\n",
    "        d:              int                 dimension of x\n",
    "        STM:            {x:fx}              dictionary of recently explored locations\n",
    "        steps:          list                a list of +/- delta for each dimension of x.\n",
    "        f_evals_count:  int                 count of total function evaluations\n",
    "        constrained:    bool                controls if we use penalty function or not\n",
    "        w_val:          int                 penalty value\n",
    "\n",
    "    returns best step x0, fx0 from the local search \n",
    "    and the updated count of total cost function evaluations.\n",
    "    '''\n",
    "\n",
    "    x_best = None\n",
    "    fx_best = None\n",
    "\n",
    "    while len(steps) > 0:\n",
    "        step = steps.pop()\n",
    "        x_best, fx_best, f_evals_count = search(base, step, STM, x_best, fx_best, \n",
    "                                                            constrained, f_evals_count, w_val)    \n",
    "    if fx_best != None:\n",
    "        if fx_best < f_base:\n",
    "            x_best, fx_best, f_evals_count = pattern(x_best, fx_best, base, constrained, w_val, f_evals_count)\n",
    "\n",
    "    if fx_best == None:\n",
    "        x_best = base\n",
    "        fx_best = f_base\n",
    "    return x_best, fx_best, f_evals_count\n",
    "\n",
    "def random_subset(base, f_base, d, P, STM, steps, f_evals_count, constrained, w_val):\n",
    "    '''Perform a local search  using the random subset method for the tabu search function.\n",
    "    inputs\n",
    "        base:           d-length vector     current point x\n",
    "        f_base:         float               function evaluated at x\n",
    "        d:              int                 dimension of x\n",
    "        P:              int                 the max number of possible non-tabu moves to evaluate\n",
    "        STM:            {x:fx}              dictionary of recently explored locations\n",
    "        steps:          list                a list of +/- delta for each dimension of x.\n",
    "        f_evals_count   int                 count of total function evaluations\n",
    "        constrained:    bool                controls if we use penalty function or not\n",
    "        w_val:          int                 penalty value\n",
    "\n",
    "    returns best step x0, fx0 from the local search \n",
    "    and the updated count of total cost function evaluations.\n",
    "    '''\n",
    "    x_best = None\n",
    "    fx_best = None\n",
    "\n",
    "    for i in range(P):\n",
    "        step = steps.pop()\n",
    "        x_best, fx_best, f_evals_count = search(base, step, STM, x_best, fx_best, \n",
    "                                                            constrained, f_evals_count, w_val)    \n",
    "    if fx_best != None:\n",
    "        if fx_best < f_base:\n",
    "            x_best, fx_best, f_evals_count = pattern(x_best, fx_best, base, constrained, w_val, f_evals_count)\n",
    "    if fx_best == None:\n",
    "        x_best = base\n",
    "        fx_best = f_base\n",
    "    return x_best, fx_best, f_evals_count\n",
    "\n",
    "\n",
    "def successive_rs(base, f_base, d, P, STM, steps, f_evals_count, constrained, w_val):\n",
    "    '''Perform a local search  using the successive random subset method for the tabu search function.\n",
    "    inputs\n",
    "        base:           d-length vector     current point x\n",
    "        f_base:         float               function evaluated at x\n",
    "        d:              int                 dimension of x\n",
    "        P:              int                 the max number of possible non-tabu moves to evaluate\n",
    "        STM:            {x:fx}              dictionary of recently explored locations\n",
    "        steps:          list                a list of +/- delta for each dimension of x.\n",
    "        f_evals_count   int                 count of total function evaluations\n",
    "        constrained:    bool                controls if we use penalty function or not\n",
    "        w_val:          int                 penalty value\n",
    "\n",
    "    returns best step x0, fx0 from the local search \n",
    "    and the updated count of total cost function evaluations.\n",
    "    '''\n",
    "    x_best = None\n",
    "    fx_best =  None\n",
    "    improved = False\n",
    "\n",
    "    while not improved and len(steps) > 0:\n",
    "        if len(steps) > P:\n",
    "            subset = [steps.pop() for _ in range(P)]\n",
    "        else:\n",
    "            subset = steps.copy()\n",
    "            steps = []\n",
    "        \n",
    "        for step in subset:\n",
    "            x_best, fx_best, f_evals_count = search(base, step, STM, x_best, fx_best, \n",
    "                                                            constrained, f_evals_count, w_val)\n",
    "            if fx_best != None:  \n",
    "                if fx_best < f_base:\n",
    "                    improved = True    \n",
    "\n",
    "    if improved:\n",
    "        x_best, fx_best, f_evals_count = pattern(x_best, fx_best, base, constrained, w_val, f_evals_count)\n",
    "    if fx_best == None:\n",
    "        x_best = base\n",
    "        fx_best = f_base\n",
    "    return x_best, fx_best, f_evals_count\n",
    "\n",
    "def sensitivity(base, d, delta, f_evals_count, w_val):\n",
    "    '''Find the d/2 most sensitive directions.'''\n",
    "    s = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        f_plus = egg.eggholder_unconstrained(base+delta, w_val)\n",
    "        f_minus = egg.eggholder_unconstrained(base-delta, w_val)\n",
    "        s[i] = np.abs((f_plus - f_minus)/(2*delta))\n",
    "        f_evals_count += 2\n",
    "    j = d//2\n",
    "    most_sensitive_directions = sorted(range(len(s)), key=lambda i: s[i])[-j:]\n",
    "    return most_sensitive_directions, f_evals_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### MTM and STM Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_MTM(x0, fx0, M, MTM):\n",
    "    '''Updates the Medium-Term Memory (MTM) if Necessary.\n",
    "    inputs\n",
    "        MTM:        {fx:x}              current set of points in MTM\n",
    "        x0:         d-length vector     new trial point\n",
    "        fx0:        float               evaluation at new point\n",
    "        M:          int                 max size of MTM\n",
    "    \n",
    "    returns updated MTM.\n",
    "    '''\n",
    "    if len(MTM) < M:\n",
    "        MTM[fx0] = x0\n",
    "    else:\n",
    "        MTM_list = [*MTM]\n",
    "        worst = min(MTM_list)\n",
    "        if fx0 < worst:\n",
    "            del MTM[worst]\n",
    "            MTM[fx0] = x0\n",
    "    \n",
    "    return MTM\n",
    "\n",
    "def update_counter(x0, fx0, best_sln, counter):\n",
    "    '''update the counter and best solution.'''\n",
    "    if fx0 < best_sln[0]:\n",
    "        best_sln = [fx0,x0]\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "    \n",
    "    return counter, best_sln\n",
    "\n",
    "def update_STM(x0, N, STM):\n",
    "    '''Update the Short-Term Memory (STM).'''\n",
    "    STM.append(x0)\n",
    "    while len(STM) > N:\n",
    "        STM.pop()\n",
    "    return STM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Long-Term Memory (LTM) Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_increase(sector, d, split):\n",
    "    '''Used in the initialisation of the LTM. Essentially for counting up in base-n, where\n",
    "    n=split, as this is how all the sectors are divided.\n",
    "    \n",
    "    inputs\n",
    "        sector:     d-length list       each element is in range(0,split). This is the most\n",
    "                                        recently appended sector to the LTM initialisation.\n",
    "        d:          int                 dimension of x\n",
    "        split:      int                 number of sections that each variable is split into\n",
    "    \n",
    "    returns the index that should be increased for the next sector to append to the LTM. \n",
    "    If all sectors have been appended (all values in sector = (split-1)), then return -1.\n",
    "    '''\n",
    "    for i in range(d):\n",
    "        if sector[i] != split-1:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def init_LTM(d, split, sector, LTM):\n",
    "    '''Creates an LTM with a key for each sector according to the specified dimension \n",
    "    and split.\n",
    "\n",
    "    inputs\n",
    "        d:          int             dimension of x\n",
    "        split:      int             number of sections that each variable is split into.\n",
    "        sector:     d-length list   The most recently appended sector\n",
    "        LTM         {sector: count} All counts initialised to 0. Once filled with all\n",
    "                                    sectors this is returned.\n",
    "\n",
    "    returns the initialised LTM with a key for every sector needed.\n",
    "    '''\n",
    "    i = index_to_increase(sector,d,split)\n",
    "    if i == -1:\n",
    "        return(LTM)\n",
    "    elif i > 0:\n",
    "        for j in range(i):\n",
    "            sector[j] = 0\n",
    "    sector[i] += 1\n",
    "    LTM[tuple(sector)] = 0\n",
    "    return init_LTM(d, split, sector, LTM)\n",
    "\n",
    "def update_LTM(x0, d, LTM, split):\n",
    "    '''Find the sector that the new point is in and increment the count\n",
    "    for that sector. returns the updated LTM.'''\n",
    "    location = [0]*d\n",
    "    sector_width = 1024/split\n",
    "    for i in range(d):\n",
    "        for j in range(split):\n",
    "            if x0[i] >= -512 + j*sector_width and x0[i] < (-512 + (j+1)*sector_width):\n",
    "                location[i] = j\n",
    "    location = tuple(location)\n",
    "    LTM[location] += 1\n",
    "    return LTM\n",
    "\n",
    "def diversify_x(LTM, d, split):\n",
    "    '''Carries out a diversification step and returns a randomly found\n",
    "    x within the least populated sector.'''\n",
    "    sector_width = 1024/split\n",
    "    values = [*LTM.values()]\n",
    "    min_index = values.index(min(values))\n",
    "    keys = [*LTM.keys()]\n",
    "    sector = keys[min_index]\n",
    "    new_x = np.zeros(d)\n",
    "    for i, j in enumerate(sector):\n",
    "        range_min = -512 + j*sector_width\n",
    "        range_max = -512 + (j+1)*sector_width\n",
    "        new_x[i] = np.random.uniform(range_min, range_max)\n",
    "        \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Main TS Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TS_run(d, seed = 1, search_method = 0, init_step_size = 500, P = 6, split = 2, N=7, M=4, run_name = 'initial', \n",
    "            intensify = 10, diversify = 15, reduce = 25, prioritise= 6, constrained=True, w_val = 1e6, alpha = 0.9):\n",
    "    '''Conduct a run of Tabu Search under specified conditions.\n",
    "    inputs\n",
    "        d:              int     dimension of datapoints.\n",
    "        seed:           float   random seed for different runs\n",
    "        search_method:  int     choose which local search method to use.\n",
    "        init_step_size: int     starting step size to take\n",
    "        P:              int     the number of steps to evaluate in each cycle for rs.\n",
    "        split:          int     the number of splits per variable for creating sectors.\n",
    "        N:              int     size of STM\n",
    "        M:              int     size of MTM\n",
    "        run_name:       str     identifier for the run if required\n",
    "        intensify:      int     value of counter at which to intensify search\n",
    "        diversify:      int     value of counter at which to diversify search\n",
    "        reduce:         int     value of counter at which to reduce search\n",
    "        prioritise:     int     number of iterations in variable prioritisation before reevaluating\n",
    "        constrained:    bool    controls whether we are using a constrained formulation or not\n",
    "        w_val           int     weights on the penalty function for the unconstrained formulation\n",
    "        alpha           float   the ratio to reduce step size by on reduce steps.\n",
    "\n",
    "    returns the progress in best solution over iterations for the specified setting.\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    x0 = inar.init_x(1, d)\n",
    "    fx0 = egg.eggholder(x0)\n",
    "    counter = 0\n",
    "    step_size = init_step_size\n",
    "    f_evals_count = 0\n",
    "    STM = []\n",
    "    MTM = {fx0: x0.copy()}\n",
    "    first_sector = [0]*d\n",
    "    LTM = init_LTM(d, split, first_sector, {tuple(first_sector):0})\n",
    "    prioritisation_count = 0\n",
    "    directions = [0]\n",
    "\n",
    "    path = {fx0:x0.copy()}\n",
    "    archive = {fx0:x0.copy()}\n",
    "    fx_progress = []\n",
    "    f_evals_count_list = []\n",
    "\n",
    "    best_sln = [fx0, x0]\n",
    "    while step_size > 1e-4 and f_evals_count < 15000:\n",
    "        steps = poss_steps(d, step_size)\n",
    "        if search_method == 0:\n",
    "            random.shuffle(steps)\n",
    "            x0, fx0, f_evals_count = local_search_basic(x0.copy(), fx0.copy(), d, STM, steps, \n",
    "                                                        f_evals_count, constrained, w_val)\n",
    "        elif search_method == 1:\n",
    "            random.shuffle(steps)\n",
    "            x0, fx0, f_evals_count = random_subset(x0.copy(), fx0.copy(), d, P, STM, steps, \n",
    "                                                    f_evals_count, constrained, w_val)\n",
    "        elif search_method == 2:\n",
    "            random.shuffle(steps)\n",
    "            x0, fx0, f_evals_count = successive_rs(x0.copy(), fx0.copy(), d, P, STM, steps, \n",
    "                                                    f_evals_count, constrained, w_val)\n",
    "        else:\n",
    "            if prioritisation_count >= prioritise or f_evals_count == 0:\n",
    "                directions, f_evals_count = sensitivity(x0.copy(), d, step_size, \n",
    "                                                        f_evals_count, w_val)\n",
    "                prioritisation_count = 0\n",
    "            prioritisation_count += 1\n",
    "            chosen_steps = []\n",
    "            for direction in directions:\n",
    "                chosen_steps.append(steps[2*direction])\n",
    "                chosen_steps.append(steps[2*direction + 1])\n",
    "            random.shuffle(chosen_steps)\n",
    "            x0, fx0, f_evals_count = local_search_basic(x0.copy(), fx0.copy(), d, STM, chosen_steps, \n",
    "                                                        f_evals_count, constrained, w_val)\n",
    "                    \n",
    "        archive, updated = inar.update_archive(x0, fx0, archive)\n",
    "        path[fx0] = x0.copy()\n",
    "        counter, best_sln = update_counter(x0, fx0, best_sln, counter)\n",
    "        fx_progress.append(best_sln[0])\n",
    "        f_evals_count_list.append(f_evals_count)\n",
    "        STM = update_STM(x0.copy(), N, STM)\n",
    "        MTM = update_MTM(x0.copy(), fx0, M, MTM)\n",
    "        LTM = update_LTM(x0.copy(), d, LTM, split)\n",
    "        \n",
    "        if counter == intensify:\n",
    "            vals = np.array([*MTM.values()])\n",
    "            x0 = np.mean(vals, axis=0)\n",
    "        elif counter == diversify:\n",
    "            xnew = diversify_x(LTM, d, split)\n",
    "            x0 = xnew\n",
    "            \n",
    "        elif counter == reduce:\n",
    "            step_size *= alpha\n",
    "            counter = 0\n",
    "            fx0 = best_sln[0]\n",
    "            x0 = best_sln[1]\n",
    "            continue\n",
    "        \n",
    "        if constrained:\n",
    "            fx0 = egg.eggholder(x0)\n",
    "        else:\n",
    "            fx0 = egg.eggholder_unconstrained(x0, w_val)\n",
    "        f_evals_count += 1\n",
    "\n",
    "    fx_star = min([*archive])\n",
    "    print(\"\\nBest solution: \\n\", fx_star, archive[fx_star])  \n",
    "    print(len(path))\n",
    "    print(len(archive))\n",
    "\n",
    "    z = []\n",
    "    if d==2:\n",
    "        # Draw contour plot and evolution of best solution found across iterations\n",
    "        z = egg.plot_eggholder2D(archive, path, run_name)\n",
    "    egg.plot_progress(fx_progress, z, d, run_name, f_evals_count_list)\n",
    "    # return fx_progress, f_evals_count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_run(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Large Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Changing Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_progress_dict = {}\n",
    "f_evals_count_dict = {}\n",
    "\n",
    "d=6\n",
    "for alpha in [0.85, 0.9, 0.95, 0.99]:\n",
    "    graph_name = 'a: {}'.format(alpha)\n",
    "    print(graph_name)\n",
    "    progress_list = []\n",
    "    f_evals_count_list = []\n",
    "    for i in tqdm(range(100)):\n",
    "        f_progress, f_evals = TS_run(d, i, 0, 100, constrained=True, alpha=alpha)\n",
    "        progress_list.append(f_progress)\n",
    "        f_evals_count_list.append(f_evals)\n",
    "    fx_progress_dict[graph_name] = progress_list\n",
    "    f_evals_count_dict[graph_name] = f_evals_count_list\n",
    "\n",
    "\n",
    "egg.plot_progress_multvar(fx_progress_dict, d, 'TS_alpha_step100', True, f_evals_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Changing Step Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_progress_dict = {}\n",
    "f_evals_count_dict = {}\n",
    "\n",
    "d=6\n",
    "for init_step in [50, 100, 200, 500]:\n",
    "    graph_name = 'step: {}'.format(init_step)\n",
    "    print(graph_name)\n",
    "    progress_list = []\n",
    "    f_evals_count_list = []\n",
    "    for i in tqdm(range(100)):\n",
    "        f_progress, f_evals = TS_run(d, i, 0, init_step, constrained=True)\n",
    "        progress_list.append(f_progress)\n",
    "        f_evals_count_list.append(f_evals)\n",
    "    fx_progress_dict[graph_name] = progress_list\n",
    "    f_evals_count_dict[graph_name] = f_evals_count_list\n",
    "\n",
    "egg.plot_progress_multvar(fx_progress_dict, d, 'TS_step_size', True, f_evals_count_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Random Subset Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_progress_dict = {}\n",
    "f_evals_count_dict = {}\n",
    "\n",
    "d=6\n",
    "for p in [2, 4, 6, 9]:\n",
    "    graph_name = 'P: {}'.format(p)\n",
    "    print(graph_name)\n",
    "    progress_list = []\n",
    "    f_evals_count_list = []\n",
    "    for i in tqdm(range(100)):\n",
    "        f_progress, f_evals = TS_run(d, i, 1, P = p)\n",
    "        progress_list.append(f_progress)\n",
    "        f_evals_count_list.append(f_evals)\n",
    "    fx_progress_dict[graph_name] = progress_list\n",
    "    f_evals_count_dict[graph_name] = f_evals_count_list\n",
    "\n",
    "egg.plot_progress_multvar(fx_progress_dict, d, 'RS', True, f_evals_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Successive RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_progress_dict = {}\n",
    "f_evals_count_dict = {}\n",
    "\n",
    "d=6\n",
    "for p in [4, 6, 8, 10]:\n",
    "    graph_name = 'P: {}'.format(p)\n",
    "    print(graph_name)\n",
    "    progress_list = []\n",
    "    f_evals_count_list = []\n",
    "    for i in tqdm(range(100)):\n",
    "        f_progress, f_evals = TS_run(d, i, 2, P = p)\n",
    "        progress_list.append(f_progress)\n",
    "        f_evals_count_list.append(f_evals)\n",
    "    fx_progress_dict[graph_name] = progress_list\n",
    "    f_evals_count_dict[graph_name] = f_evals_count_list\n",
    "    \n",
    "egg.plot_progress_multvar(fx_progress_dict, d, 'successive_RS', True, f_evals_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variable Prioritisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_progress_dict = {}\n",
    "f_evals_count_dict = {}\n",
    "\n",
    "d=6\n",
    "for count in [6, 10, 20, 40]:\n",
    "    graph_name = 'count: {}'.format(count)\n",
    "    print(graph_name)\n",
    "    progress_list = []\n",
    "    f_evals_count_list = []\n",
    "    for i in tqdm(range(100)):\n",
    "        f_progress, f_evals = TS_run(d, i, 3, prioritise=count)\n",
    "        progress_list.append(f_progress)\n",
    "        f_evals_count_list.append(f_evals)\n",
    "    fx_progress_dict[graph_name] = progress_list\n",
    "    f_evals_count_dict[graph_name] = f_evals_count_list\n",
    "\n",
    "egg.plot_progress_multvar(fx_progress_dict, d, 'var_prioritisation', True, f_evals_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Constrained Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_progress_dict = {}\n",
    "f_evals_count_dict = {}\n",
    "\n",
    "d=6\n",
    "constrained = False\n",
    "for w in [0, 1e3, 1e5, 1e6, 1e9]:\n",
    "    graph_name = 'w: {}'.format(w)\n",
    "    if w == 0:\n",
    "        constrained = True\n",
    "        graph_name = 'Constrained'\n",
    "    print(graph_name)\n",
    "    progress_list = []\n",
    "    f_evals_count_list = []\n",
    "    for i in tqdm(range(100)):\n",
    "        f_progress, f_evals = TS_run(d, i, 1, constrained=constrained, w_val = w)\n",
    "        progress_list.append(f_progress)\n",
    "        f_evals_count_list.append(f_evals)\n",
    "    fx_progress_dict[graph_name] = progress_list\n",
    "    f_evals_count_dict[graph_name] = f_evals_count_list\n",
    "\n",
    "egg.plot_progress_multvar(fx_progress_dict, d, 'unconstrained', True, f_evals_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### M and N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_progress_dict = {}\n",
    "f_evals_count_dict = {}\n",
    "\n",
    "N_vals = [7,20,40, 80]\n",
    "M_vals = [4,15,30, 60]\n",
    "\n",
    "d=6\n",
    "for index,M in enumerate(M_vals):\n",
    "    N = N_vals[index]\n",
    "    graph_name = 'N: {}, M: {}'.format(N, M)\n",
    "    print(graph_name)\n",
    "    progress_list = []\n",
    "    f_evals_count_list = []\n",
    "    for i in tqdm(range(100)):\n",
    "        f_progress, f_evals = TS_run(d, i, 1, N=N, M=M)\n",
    "        progress_list.append(f_progress)\n",
    "        f_evals_count_list.append(f_evals)\n",
    "    fx_progress_dict[graph_name] = progress_list\n",
    "    f_evals_count_dict[graph_name] = f_evals_count_list\n",
    "\n",
    "egg.plot_progress_multvar(fx_progress_dict, d, 'NM2', True, f_evals_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Parameter Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_progress_dict = {}\n",
    "f_evals_count_dict = {}\n",
    "\n",
    "intensify_vals = [8, 10, 20, 40]\n",
    "diversify_vals = [12, 15, 30, 60]\n",
    "reduce_vals = [20, 25, 50, 100]\n",
    "\n",
    "d=6\n",
    "for index,I in enumerate(intensify_vals):\n",
    "    D = diversify_vals[index]\n",
    "    R = reduce_vals[index]\n",
    "    graph_name = 'I: {}, D: {}, R: {}'.format(I, D, R)\n",
    "    print(graph_name)\n",
    "    progress_list = []\n",
    "    f_evals_count_list = []\n",
    "    for i in tqdm(range(100)):\n",
    "        f_progress, f_evals = TS_run(d, i, 1, intensify=I, diversify=D, reduce=R)\n",
    "        progress_list.append(f_progress)\n",
    "        f_evals_count_list.append(f_evals)\n",
    "    fx_progress_dict[graph_name] = progress_list\n",
    "    f_evals_count_dict[graph_name] = f_evals_count_list\n",
    "\n",
    "egg.plot_progress_multvar(fx_progress_dict, d, 'IDR', True, f_evals_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_progress_dict = {}\n",
    "f_evals_count_dict = {}\n",
    "\n",
    "d=6\n",
    "for split in [2,3]:\n",
    "    graph_name = 'Split: {}'.format(split)\n",
    "    print(graph_name)\n",
    "    progress_list = []\n",
    "    f_evals_count_list = []\n",
    "    for i in tqdm(range(100)):\n",
    "        f_progress, f_evals = TS_run(d, i, 1,split=split, intensify=20, diversify=30, reduce=50)\n",
    "        progress_list.append(f_progress)\n",
    "        f_evals_count_list.append(f_evals)\n",
    "    fx_progress_dict[graph_name] = progress_list\n",
    "    f_evals_count_dict[graph_name] = f_evals_count_list\n",
    "\n",
    "egg.plot_progress_multvar(fx_progress_dict, d, 'Split', True, f_evals_count_dict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
